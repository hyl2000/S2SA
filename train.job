#!/bin/sh
#SBATCH --job-name=S2SA
#SBATCH -o ./S2SA.train-%A.out
#SBATCH -e ./S2SA.train-%A.err
#SBATCH --nodelist=ilps-cn115
#SBATCH -p gpu
#SBATCH --gres=gpu:4
#SBATCH -c8
#SBATCH --mem=20G
#SBATCH --time=2-00:00:00

# echo run info
echo "SLURM_SUBMIT_DIR="$SLURM_SUBMIT_DIR
echo "SLURM_JOB_ID"=$SLURM_JOB_ID 
echo "SLURM_JOB_NAME"=$SLURM_JOB_NAME

# Set-up the environment.
source ${HOME}/.bashrc
conda activate env_pytorch

# Start the experiment.
python -m torch.distributed.launch --nproc_per_node=4  Run_S2SA.py --mode='train'
